{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dca9000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyMuPDF\n",
      "  Downloading PyMuPDF-1.23.2-cp310-none-win_amd64.whl (3.5 MB)\n",
      "     ---------------------------------------- 3.5/3.5 MB 4.0 MB/s eta 0:00:00\n",
      "Collecting PyMuPDFb==1.23.0\n",
      "  Downloading PyMuPDFb-1.23.0-py3-none-win_amd64.whl (22.7 MB)\n",
      "     ---------------------------------------- 22.7/22.7 MB 5.7 MB/s eta 0:00:00\n",
      "Installing collected packages: PyMuPDFb, PyMuPDF\n",
      "Successfully installed PyMuPDF-1.23.2 PyMuPDFb-1.23.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install PyMuPDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd6a2852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "     -------------------------------------- 232.6/232.6 kB 3.5 MB/s eta 0:00:00\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "     ---------------------------------------- 86.0/86.0 kB 4.7 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting transformers<5.0.0,>=4.6.0\n",
      "  Downloading transformers-4.32.1-py3-none-any.whl (7.5 MB)\n",
      "     ---------------------------------------- 7.5/7.5 MB 5.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in c:\\users\\rohit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (4.64.1)\n",
      "Collecting torch>=1.6.0\n",
      "  Downloading torch-2.0.1-cp310-cp310-win_amd64.whl (172.3 MB)\n",
      "     -------------------------------------- 172.3/172.3 MB 3.7 MB/s eta 0:00:00\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.15.2-cp310-cp310-win_amd64.whl (1.2 MB)\n",
      "     ---------------------------------------- 1.2/1.2 MB 3.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\rohit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (1.23.5)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\rohit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\rohit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (1.9.3)\n",
      "Requirement already satisfied: nltk in c:\\users\\rohit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (3.8.1)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.99-cp310-cp310-win_amd64.whl (977 kB)\n",
      "     -------------------------------------- 977.5/977.5 kB 3.6 MB/s eta 0:00:00\n",
      "Collecting huggingface-hub>=0.4.0\n",
      "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "     -------------------------------------- 268.8/268.8 kB 4.2 MB/s eta 0:00:00\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.12.3-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\rohit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (22.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\rohit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.4.0)\n",
      "Collecting fsspec\n",
      "  Downloading fsspec-2023.6.0-py3-none-any.whl (163 kB)\n",
      "     -------------------------------------- 163.8/163.8 kB 5.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in c:\\users\\rohit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.28.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\rohit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rohit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
      "Collecting sympy\n",
      "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "     ---------------------------------------- 5.7/5.7 MB 4.8 MB/s eta 0:00:00\n",
      "Collecting networkx\n",
      "  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "     ---------------------------------------- 2.1/2.1 MB 6.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\rohit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\rohit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.8.8)\n",
      "Collecting safetensors>=0.3.1\n",
      "  Downloading safetensors-0.3.3-cp310-cp310-win_amd64.whl (266 kB)\n",
      "     -------------------------------------- 266.1/266.1 kB 8.3 MB/s eta 0:00:00\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp310-cp310-win_amd64.whl (3.5 MB)\n",
      "     ---------------------------------------- 3.5/3.5 MB 6.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: click in c:\\users\\rohit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk->sentence-transformers) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\rohit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\rohit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\rohit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision->sentence-transformers) (9.3.0)\n",
      "Collecting typing-extensions>=3.7.4.3\n",
      "  Downloading typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rohit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\rohit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\rohit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rohit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rohit\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "     -------------------------------------- 536.2/536.2 kB 6.7 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py): started\n",
      "  Building wheel for sentence-transformers (setup.py): finished with status 'done'\n",
      "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125960 sha256=467b3f0114b026211c5ca1a7c4a131e216822bc64b96eb5b381acefffe28a8a2\n",
      "  Stored in directory: c:\\users\\rohit\\appdata\\local\\pip\\cache\\wheels\\62\\f2\\10\\1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
      "Successfully built sentence-transformers\n",
      "Installing collected packages: tokenizers, sentencepiece, safetensors, mpmath, typing-extensions, sympy, PyPDF2, networkx, fsspec, filelock, torch, huggingface-hub, transformers, torchvision, sentence-transformers\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.4.0\n",
      "    Uninstalling typing_extensions-4.4.0:\n",
      "      Successfully uninstalled typing_extensions-4.4.0\n",
      "Successfully installed PyPDF2-3.0.1 filelock-3.12.3 fsspec-2023.6.0 huggingface-hub-0.16.4 mpmath-1.3.0 networkx-3.1 safetensors-0.3.3 sentence-transformers-2.2.2 sentencepiece-0.1.99 sympy-1.12 tokenizers-0.13.3 torch-2.0.1 torchvision-0.15.2 transformers-4.32.1 typing-extensions-4.7.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install PyPDF2 sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f9cb2068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference Found Sentence No : 4\n",
      "Difference Found Sentence No : 5\n",
      "Difference Found Sentence No : 7\n",
      "Difference Found Sentence No : 16\n",
      "Difference Found Sentence No : 21\n",
      "Difference Found Sentence No : 30\n",
      "Difference Found Sentence No : 32\n",
      "Difference Found Sentence No : 36\n",
      "Difference Found Sentence No : 39\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Function to extract text from a PDF file\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    with open(pdf_path, \"rb\") as pdf_file:\n",
    "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "        for page in pdf_reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "# Paths to the two PDFs you want to compare\n",
    "pdf_path1 = \"Email1.pdf\"\n",
    "pdf_path2 = \"Email2.pdf\"\n",
    "\n",
    "# Extract text from the PDFs\n",
    "text1 = extract_text_from_pdf(pdf_path1)\n",
    "text2 = extract_text_from_pdf(pdf_path2)\n",
    "\n",
    "# Load a pre-trained sentence embeddings model\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "# Generate embeddings for sentences\n",
    "sentences1 = [sentence.strip() for sentence in text1.split(\".\") if sentence.strip()]\n",
    "sentences2 = [sentence.strip() for sentence in text2.split(\".\") if sentence.strip()]\n",
    "\n",
    "# Calculate cosine similarities between sentence embeddings\n",
    "sentence_embeddings1 = model.encode(sentences1, convert_to_tensor=True)\n",
    "sentence_embeddings2 = model.encode(sentences2, convert_to_tensor=True)\n",
    "\n",
    "cosine_similarities = util.pytorch_cos_sim(sentence_embeddings1, sentence_embeddings2)\n",
    "\n",
    "# Print similarity scores for each sentence pair\n",
    "i=0\n",
    "j=0\n",
    "for i in range(min(len(sentences1), len(sentences2))):\n",
    "    similarity = cosine_similarities[i][j].item()  # Compare parallel sentences\n",
    "    # print(f\"Similarity between Sentence {i+1} from PDF 1 and Sentence {i+1} from PDF 2: {similarity:.4f}\")\n",
    "    j=j+1\n",
    "    # Highlight sentence pairs with similarity less than 1\n",
    "    # if similarity < 1.0:\n",
    "    #     print(\"   *** Similarity < 1 ***\")\n",
    "    \n",
    "    if round(similarity,4) < 1.0 :\n",
    "        print(f\"Difference Found Sentence No : {i+1}\")\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d94841b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
